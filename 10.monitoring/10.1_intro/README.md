Домашнее задание к занятию "13.Системы мониторинга"
-----

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

Значит у нас web-сервис с бекендом, который выполняет вычисления. Скорее всего варианта 2: либо LAMP, либо LEMP + reverse proxy, следовательно будем мониторить:

## Железо/vm
 * доступность vm по ping
 * параметры блочных устройств (свободное место, iops, iowait, inodes)
 * параметры cpu/ram (LA, утилизация)
 * пропускная способность канала связи
 * статус демона web-сервера, БД

## Web-сервис
 * доступность web - например curl с парсингом какого-нибудь элемета главной страницы через regexp
 * срок жизни ssl сертификатов
 * время отклика
 * количество 400/500х ошибок

## BD
 * Параметры утилизации
 * Количество вх/вых данных
 * Количество соединений (у БД без bouncer'a лимит около 1к)
 * Количество ошибок
 * Время выполнения запросов
 * Соотношение hit/miss
  
#

2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

Указанные параметры можно соотнести с ключевыми  показателями обслуживания. Как правило в отказоустойчивых системах они исчисляются "девятками", которые выражаются в количестве времени недоступности системы в течении определенного времени, например:

|SLA|Время недоступности в год|
|--|--|
|99|3д 15ч 39м 30с|
|99.9|8ч 45м 57с|
|99.99|52м 36с|

Таким образом можно вычислить количество времени, в течении которого сервис может быть недоступен и при этом будут соблюдены ключевые показатели обслуживания. В высоконадежных и отказоустойчивых системах, в которых не бывает простоя, иногда намеренно делают сервис недоступным, чтобы не превышать SLА.

Управление SLA, SLO и SLI очень хорошо расписано в одной из первых глав книги "SRE надежность как в Google".

#

3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

На рынке существует несколько наиболее популярных стеков для системы логирования - ELK (Elasticsearch (Opensearch), Logstash, Kibana), TIG(Telegraf, InfluxDB, Grafana)/TICK, VCG (Vector, Clickhouse, Grafana).

Все решения хороши в той или иной степени и имеют свои подводные камни, однако в 2020-2023, на нескольких конференциях "Highload++" приводились решения по реализации высоконагруженных систем логирования на основе стека VCG, при этом люди уходили и с ELK и с Graylog.  
Именно по этой причине я выбрал бы для развертывания стек VCG, поскольку Vector умеет в  агрегацию, фильтрафию и предобработку данных. Его можно использовать для сбора как логов, так и метрик, с последующим перенаправлением первых в ClickHouse, а вторых в Prometheus, также он написан на Go, что делает его довольно быстрым. На примере тех же Logstash или Filebeat (по информации с конференций), они были замечены в непомерных аппетитах к RAM.

#

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

Во-первых, для корректного вычисления успешных/неуспешных запросов необходимо снимать показатели с балансировщика или веб-сервера. Во вторых, помимо 200, 400 и 500-х есть еще 300е (на память не помню, есть ли они в логах). В данном случае нам нужно считать не от общего количества запросов, а от успешных+неуспешных по формуле:  
```
% SLI = (summ_2xx_requests/(summ_2xx_requests + summ_4xx_requests + summ_5xx_requests)) * 100
```

5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#
Основные плюсы pull системы мониторинга:
1. Эффективность использования ресурсов: pull система мониторинга активно собирает данные только при необходимости, что позволяет оптимизировать использование ресурсов.
2. Гибкость и настраиваемость: pull система позволяет настраивать частоту сбора данных и выбирать только необходимую информацию для мониторинга.
3. Простота внедрения: pull системы мониторинга легко интегрируются с различными приложениями и устройствами.

Основные минусы pull системы мониторинга:
1. Задержка в получении данных: так как данные собираются только при запросе, может возникать некоторая задержка в получении актуальной информации.
2. Нагрузка на сеть: при активном использовании pull системы может возникать большая нагрузка на сеть при каждом запросе на получение данных.
3. Ограниченная возможность мониторинга в режиме реального времени: pull система может не обеспечивать возможность мониторинга в режиме реального времени из-за задержки в получении данных.

Основные плюсы push системы мониторинга:
1. Мониторинг в режиме реального времени: push система мониторинга позволяет получать данные в режиме реального времени, что позволяет оперативно реагировать на изменения.
2. Минимальная задержка в получении данных: данные в push системе передаются непрерывно, что позволяет минимизировать задержку в получении актуальной информации.
3. Широкий спектр возможностей мониторинга: push системы обеспечивают больше возможностей для мониторинга различных параметров и событий.

Основные минусы push системы мониторинга:
1. Высокая нагрузка на ресурсы: push системы активно передают данные в режиме реального времени, что может приводить к высокой нагрузке на ресурсы и сеть.
2. Сложность настройки и интеграции: push системы требуют более сложной настройки и интеграции с приложениями и устройствами.
3. Потенциальные проблемы безопасности: так как push системы активно передают данные, может возникать потенциальная угроза безопасности при передаче конфиденциальной информации.

6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

- Prometheus - относится к push модели. В Prometheus агенты активно отправляют метрики и данные в Prometheus сервер.
- TICK (Telegraf, InfluxDB, Chronograf, Kapacitor) - может быть использовано как в push, так и в pull модели(гибридная). Telegraf, как мониторинговый агент, может активно отправлять метрики в InfluxDB (push модель), а также InfluxDB может запрашивать данные у Telegraf (pull модель).
- Zabbix - относится к pull модели. Zabbix сервер активно запрашивает данные у мониторинговых агентов.
- VictoriaMetrics - может быть использовано как в push, так и в pull модели(гибридная). Метрики могут быть отправлены в VictoriaMetrics (push модель), а также VictoriaMetrics может запрашивать данные у мониторинговых агентов (pull модель).
- Nagios - относится к pull модели. Nagios сервер активно запрашивает данные у мониторинговых агентов.

7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

![Alt text](image.png)

#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.  

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.

![Alt text](image-1.png)

9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

![Alt text](image-2.png)