Домашнее задание к занятию "10.6 Инцидент-менеджмент"
-----

### Задание 1
Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

ГитХаб, посмортем (сбой № 1234)  
**Дата события**: 21.10.2018  
**Дата составления**: 28.08.2023  
**Автор**: Кунаев Н.Д.  

**Краткая информация**:  
В 22:52 (21.10) по UTC на нескольких сервисах GitHub.com пострадали несколько сетевых разделов и 
последующим сбоем базы данных, что привело к появлению непоследовательной информации на нашем веб-сайте. 

**Последствия**:   
Наблюдалась деградация сервисов Issue и PR на протяжении 24 часов и 11 минут

**Исходные причины**:   
Наличие задержки в репликации записей мастер-ноды БД, а также изменение мастер-ноды в результате 
потери соединения, вызвало нарушение целостности данных из-за чего, после перевыбора лидера записи не смогли прийти в согласованное состояние.

**Событие, запустившее сбой**:  
21.10.2018, в 22:52, во время сервисных работ по замене вышедшего из строя 100G привели к 
потере соединения между сетевым концентратором на восточном побережье США и основным центром обработки данных на восточном побережье США.
Соединение между этими точками было восстановлено за 43 секунды, но этот кратковременный сбой вызвал цепочку событий, которые привели к ухудшению качества обслуживания на 24 часа и 11 минут.

**Решение**:   
Временная приостановка функций доставки вуб-хуков и сборки страниц Гитхаба для снижения нагрузки на БД, восстановление данных
на сбойных репликах из бекапов и последующая ресинхронизация.

**Обнаружение**:
Система мониторинга сообщила о сбое в состоянии реплик БД на Западном побережье.


**Таймлайн**:  

**2018 October 21 22:52 UTC**  
После сетевого сбоя протокол Raft начал переизбрание лидера. Когда соединение восстановилось, трафик вновь был перенаправлен
вновь переизбранные мастер-ноды на Западное побержье. Серверы баз данных в центре обработки данных на восточном побережье 
США содержали короткий период записей, которые не были реплицированы на объект на 
западном побережье США.  Поскольку кластеры баз данных в обоих центрах обработки данных 
теперь содержали записи, которых не было в другом центре обработки данных, перенос роли не был завершен успешно.

**2018 October 21 22:54 UTC**:  

Внутренние системы мониторинга начали генерировать оповещения, указывающие на многочисленные
сбои в системах.  В это время несколько инженеров отвечали и работали над сортировкой 
входящих уведомлений.  К 23:02 UTC инженеры группы быстрого реагирования определили, что
топологии многочисленных кластеров баз данных находятся в неожиданном состоянии. Запрос к API 
Orchestrator показал топологию репликации базы данных, которая включала только серверы из нашего 
центра обработки данных на западном побережье США.

**2018 October 21 23:07 UTC**:  

К этому моменту группа реагирования решила вручную заблокировать наши внутренние инструменты
развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений.  В 23:09 UTC
группа реагирования перевела сайт в желтый статус.  Это действие автоматически перевело ситуацию
в активный инцидент и отправило предупреждение координатору инцидента.  В 23:11 UTC присоединился
координатор инцидентов и через две минуты изменил статус решения на красный.

**2018 October 21 23:13 UTC**:  

На тот момент стало понятно, что проблема затронула несколько кластеров баз данных.  Были вызваны
дополнительные инженеры из группы разработки баз данных GitHub.  Они начали исследовать текущее
состояние, чтобы определить, какие действия необходимо предпринять, чтобы вручную настроить базу
данных Восточного побережья США в качестве основной для каждого кластера и перестроить топологию 
репликации.  Эта попытка была сложной, поскольку к этому моменту кластер базы данных Западного
побережья принимал записи с нашего уровня приложений в течение почти 40 минут.  Кроме того, в 
кластере Восточного побережья существовало несколько секунд записей, которые не были реплицированы
на Западное побережье и препятствовали репликации новых записей обратно на Восточное побережье.

Защита конфиденциальности и целостности пользовательских данных — высший приоритет GitHub. 
Стремясь сохранить эти данные, мы решили, что более 30 минут данных, записанных в центр обработки
данных на западном побережье США, не позволяют нам рассматривать другие варианты, кроме пересылки
при сбое, чтобы обеспечить безопасность пользовательских данных.  Однако приложения, работающие 
на восточном побережье и зависящие от записи информации в кластер MySQL западного побережья, в 
настоящее время не могут справиться с дополнительной задержкой, возникающей из-за прохождения
туда и обратно между странами для большинства вызовов к базе данных.  Это решение приведет к 
тому, что наш сервис станет непригодным для использования многими пользователями.  Мы считаем, 
что продолжительное ухудшение качества обслуживания стоило обеспечения согласованности данных 
наших пользователей.

**2018 October 21 23:19 UTC**:  

После запроса состояния кластеров базы данных стало ясно, что нам нужно остановить выполнение 
заданий, записывающих метаданные о таких вещах, как push-уведомления.  Мы сделали явный выбор 
частично снизить удобство использования сайта, приостановив доставку веб-перехватчиков и сборку 
страниц GitHub вместо того, чтобы поставить под угрозу данные, которые мы уже получили от
пользователей.  Другими словами, наша стратегия заключалась в том, чтобы поставить целостность 
данных выше удобства использования сайта и времени восстановления.

**2018 October 22 00:05 UTC**:  


Инженеры, участвующие в группе реагирования на инциденты, начали разработку плана по устранению 
несоответствий данных и реализации наших процедур аварийного переключения для MySQL.  Наш план
состоял в том, чтобы восстановиться из резервных копий, синхронизировать реплики на обоих сайтах,
вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди.
Мы обновили свой статус, чтобы сообщить пользователям, что мы собираемся выполнить контролируемый
переход на другой ресурс внутренней системы хранения данных.

**2018 October 22 00:41 UTC**:  
К этому времени был начат процесс резервного копирования для всех затронутых кластеров MySQL, и
инженеры следили за ходом его выполнения.  Одновременно несколько групп инженеров искали способы
ускорить передачу и восстановление без дальнейшего ухудшения удобства использования сайта или 
риска повреждения данных.

**2018 October 22 06:51 UTC**:  

Несколько кластеров завершили восстановление из резервных копий в нашем центре обработки данных на восточном побережье США и начали репликацию новых данных с западного побережья.  Это приводило к медленной загрузке сайта для страниц, которым приходилось выполнять операцию записи по межстрановой ссылке, но страницы, читающие из этих кластеров баз данных, возвращали актуальные результаты, если запрос на чтение попадал на недавно восстановленную реплику.  Другие более крупные кластеры баз данных все еще восстанавливались.

 Наши команды определили способы восстановления непосредственно с Западного побережья, чтобы преодолеть ограничения пропускной способности, вызванные загрузкой из внешнего хранилища, и были все более уверены в том, что восстановление неизбежно, а время, оставшееся для создания работоспособной топологии репликации, зависело от того, как долго это будет продолжаться. используйте репликацию, чтобы наверстать упущенное.  Эта оценка была линейно интерполирована на основе имеющихся у нас телеметрических данных репликации, а страница состояния была обновлена, чтобы установить ожидаемое время восстановления в два часа.


**2018 October 22 11:12 UTC**:  

Все первичные базы данных снова установлены на восточном побережье США.  В результате сайт стал гораздо более отзывчивым, поскольку записи теперь направлялись на сервер базы данных, который находился в том же физическом центре обработки данных, что и наш уровень приложений.  Несмотря на существенное повышение производительности, десятки реплик чтения базы данных по-прежнему отставали от основной на несколько часов.  Эти отложенные реплики привели к тому, что пользователи видели противоречивые данные при взаимодействии с нашими сервисами.  Мы распределяли нагрузку чтения по большому пулу реплик чтения, и каждый запрос к нашим сервисам имел хорошие шансы попасть в реплику чтения, которая задерживалась на несколько часов.

 В действительности время, необходимое для догона репликации, подчинялось функции затухания мощности, а не линейной траектории.  Из-за увеличения нагрузки на запись в наших кластерах баз данных, когда пользователи просыпались и начинали свой рабочий день в Европе и США, процесс восстановления занял больше времени, чем первоначально предполагалось.

**2018 October 22 13:15 UTC**:  

К этому моменту мы приближались к пиковой нагрузке трафика на GitHub.com.  Группа реагирования на инциденты обсудила дальнейшие действия.  Было ясно, что задержки репликации увеличивались, а не уменьшались в направлении к согласованному состоянию.  Ранее во время инцидента мы начали предоставлять дополнительные реплики чтения MySQL в общедоступном облаке Восточного побережья США.  Как только они стали доступны, стало проще распределить объем запросов на чтение между большим количеством серверов.  Снижение совокупного использования всех реплик чтения позволило репликации наверстать упущенное.

**2018 October 22 16:24 UTC**:  

Как только реплики были синхронизированы, мы выполнили переход на исходную топологию, решая непосредственные проблемы с задержкой и доступностью.  В рамках сознательного решения отдать приоритет целостности данных в течение более короткого окна инцидентов, мы сохранили статус службы красным, пока начали обрабатывать накопившиеся данные.

**2018 October 22 16:45 UTC**:  

На этом этапе восстановления нам пришлось сбалансировать возросшую нагрузку, связанную с отставанием, потенциально перегружая наших партнеров по экосистеме уведомлениями, и как можно быстрее вернуть наши услуги на 100%.  Было зарегистрировано более пяти миллионов событий-перехватчиков и 80 тысяч сборок страниц в очереди.

 Когда мы снова включили обработку этих данных, мы обработали около 200 000 полезных нагрузок веб-перехватчиков, которые пережили внутренний срок жизни и были удалены.  Обнаружив это, мы приостановили обработку и внесли изменения, чтобы на время увеличить TTL.

 Чтобы избежать дальнейшего снижения надежности наших обновлений статуса, мы оставались в пониженном статусе до тех пор, пока не завершили обработку всего накопившегося массива данных и не убедились, что наши услуги четко вернулись к нормальному уровню производительности.


**2018 October 22 23:03 UTC**:
Все ожидающие сборки веб-перехватчиков и страниц были обработаны, а целостность и правильная работа всех систем подтверждены.  Статус сайта изменился на зеленый.


**Планируемые и предпринятые меры по предупреждению подобных сбоев**:  
* Оптимизация конфигурации Orchestratorа, чтобы предотвратить распространение основных баз данных за пределы региональных границ.  

Действия Оркестратора вели себя так, как было настроено, несмотря на то, что наш уровень приложений не мог поддерживать это изменение топологии.  Выборы лидеров внутри региона в целом безопасны, но внезапная задержка между странами стала основным фактором, способствовавшим этому инциденту.  Это было неожиданное поведение системы, учитывая, что ранее мы не видели внутреннего сетевого раздела такого размера.
* Был ускорилн переход на новый механизм отчетности о статусе, который предоставит более обширную площадку для обсуждения активных инцидентов более четким и понятным языком.  

Хотя многие части GitHub были доступны во время инцидента, мы смогли установить только зеленый, желтый и красный статус.  Мы понимаем, что это не дает вам точного представления о том, что работает, а что нет, и в будущем мы будем отображать различные компоненты платформы, чтобы вы знали статус каждой службы.
* За несколько недель до этого инцидента мы запустили общекорпоративную инженерную инициативу по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в схеме «Active-Active-Active».  

Целью этого проекта является поддержка резервирования N+1 на уровне объекта.  Цель этой работы — выдержать полный отказ одного центра обработки данных без воздействия на пользователя.  Это серьезная работа, и она займет некоторое время, но мы считаем, что несколько сайтов с хорошими связями в географическом регионе обеспечивают хороший набор компромиссов.  Этот инцидент добавил срочности этой инициативе.
